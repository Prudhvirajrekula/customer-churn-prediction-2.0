import streamlit as st
import pandas as pd
import joblib
import numpy as np
import os
import random
import requests
from datetime import datetime


# âœ… Securely load API key with Streamlit fallback
OPENROUTER_API_KEY = st.secrets.get("OPENROUTER_API_KEY")

st.write("âœ… Secret loaded?", bool(OPENROUTER_API_KEY))
st.write("ğŸ”‘ Starts with sk-or?", OPENROUTER_API_KEY.startswith("sk-or") if OPENROUTER_API_KEY else "âŒ")


API_URL = "https://openrouter.ai/api/v1/chat/completions"
st.set_page_config(page_title="Muffin Chatbot", layout="wide")


# ---------------- MODELS ----------------
FREE_MODELS = {
    "Mistral 7B": "mistralai/mistral-7b-instruct:free",
    "LLaMA 3 (8B)": "meta-llama/llama-3-8b-instruct",
    "MythoMax 13B": "gryphe/mythomax-l2-13b"
}

# ---------------- STYLES ----------------
st.markdown("""
<style>
.chat-container {
    padding: 1rem;
    max-height: 70vh;
    overflow-y: auto;
}
.chat-bubble-user {
    background-color: #1f77b4;
    color: white;
    padding: 0.75rem 1rem;
    border-radius: 15px;
    margin-bottom: 5px;
    margin-left: auto;
    max-width: 70%;
    text-align: right;
}
.chat-bubble-bot {
    background-color: #333;
    color: white;
    padding: 0.75rem 1rem;
    border-radius: 15px;
    margin-bottom: 5px;
    margin-right: auto;
    max-width: 70%;
    text-align: left;
}
.chat-timestamp {
    font-size: 0.7rem;
    color: gray;
    margin: 2px 0 12px 0;
    text-align: right;
}
.spinner-beside {
    display: flex;
    align-items: center;
    gap: 10px;
    margin-top: 1rem;
}
/* Base Sidebar Style */
.sidebar-title {
    font-size: 20px;
    font-weight: 700;
    color: #f1f5f9;
    margin-bottom: 15px;
}

.metric-card {
    padding: 12px 16px;
    border-radius: 12px;
    background-color: #1e293b;
    border: 1px solid #334155;
    margin-bottom: 12px;
    box-shadow: 0 1px 2px rgba(0,0,0,0.15);
}

.metric-title {
    font-size: 13px;
    font-weight: 500;
    color: #94a3b8;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    margin-bottom: 4px;
}

.metric-value {
    font-size: 16px;
    font-weight: 600;
    color: #f8fafc;
}

.active-model {
    background-color: #0f766e;
    border: 1px solid #14b8a6;
    color: white;
    padding: 10px;
    border-radius: 10px;
    font-size: 13px;
    margin-top: 10px;
    text-align: center;
}

.section-divider {
    margin-top: 25px;
    padding-top: 15px;
    border-top: 1px solid #334155;
}

/* Tweak expanders */
.css-1xarl3l, .st-expander {
    background-color: #0f172a !important;
    border: 1px solid #334155 !important;
    border-radius: 10px;
}

.css-q8sbsg p, .css-1xarl3l p {
    color: #f1f5f9 !important;
}
</style>
""", unsafe_allow_html=True)

# ---------------- UTILS ----------------
def format_customer_context(row):
    return "\n".join([f"{col}: {row[col]}" for col in row.index])

def is_casual_input(text):
    return text.strip().lower() in ["hi", "hello", "hey", "yo", "how are you", "how's your day", "how was your day", "what's up"]

def casual_response():
    return random.choice([
        "Hey there! ğŸ‘‹",
        "Hi! I'm Muffin, your churn buddy.",
        "Hello! Ask me anything about your customer.",
        "Yo! Ready to dive into churn data?"
    ])

# ---------- Load Model & Data First ----------
model = joblib.load("models/model.pkl")
df = pd.read_csv("data/model_features.csv").dropna()
df = df[:100]
# ---------------- SIDEBAR ----------------
with st.sidebar:
    st.markdown("""
    <style>
        .sidebar-header {
            margin-bottom: 25px;
            padding-bottom: 10px;
            border-bottom: 1px solid #e1e4e8;
        }
        .sidebar-title {
            font-size: 22px;
            font-weight: 700;
            color: #1e293b;
        }
        .metric-card {
            padding: 10px 12px;
            border-radius: 10px;
            background-color: #f9fafb;
            margin-bottom: 10px;
            border: 1px solid #e2e8f0;
        }
        .metric-title {
            font-size: 12px;
            font-weight: 600;
            color: #64748b;
            text-transform: uppercase;
        }
        .metric-value {
            font-size: 14px;
            font-weight: 600;
            color: #1e293b;
        }
        .active-model {
            background-color: #f0fdf4;
            border: 1px solid #bbf7d0;
            color: #166534;
            padding: 10px;
            border-radius: 8px;
            font-size: 13px;
            margin-top: 10px;
        }
        .section-divider {
            margin-top: 25px;
            padding-top: 15px;
            border-top: 1px solid #e1e4e8;
        }
    </style>
    
    <div class="sidebar-header">
        <h1 class="sidebar-title">ğŸ”§ Muffin Analytics</h1>
    </div>
    """, unsafe_allow_html=True)

    # --- Model Selector ---
    st.markdown('<h4 class="sidebar-title">ğŸ§  Select LLM Model</h4>', unsafe_allow_html=True)
    selected_model_label = st.selectbox(
        "Choose LLM engine",
        options=list(FREE_MODELS.keys()),
        index=0,
        key="model_selector"
    )
    MODEL_NAME = FREE_MODELS[selected_model_label]

    st.markdown(f"""
    <div class="active-model">
        âœ… <strong>Using:</strong><br> {selected_model_label}
    </div>
    """, unsafe_allow_html=True)


    # --- Customer Profile ---
    st.markdown('<h4 class="sidebar-title">ğŸ‘¤ Customer Profile</h4>', unsafe_allow_html=True)
    with st.expander("Expand Profile Details", expanded=True):
        customer_idx = st.slider(
            "Select customer profile:",
            0, len(df) - 1, 0,
            label_visibility="collapsed"
        )
        customer = df.iloc[customer_idx]

        st.markdown(f"""
        <div style="margin-top: 10px; margin-bottom: 10px;">
            <strong style="font-size:20px;">ğŸ“„ Customer ID:</strong> <span style="color: #ebeced;">{customer_idx}</span>
        </div>
        """, unsafe_allow_html=True)

        st.markdown('<h4 class="sidebar-title">ğŸ“ŠSummary</h4>', unsafe_allow_html=True)
        cols = st.columns(2)
        for i, col in enumerate(customer.index):
            with cols[i % 2]:
                display_value = f"{customer[col]:,.0f}" if isinstance(customer[col], (int, float)) else customer[col]
                st.metric(label=col.replace('_', ' ').title(), value=display_value)
        

        # âœ… INSERT HERE: Real-Time Metrics
        st.markdown('<h4 class="sidebar-title">ğŸ“ˆ Real-Time Metrics</h4>', unsafe_allow_html=True)
        st.metric("ğŸ›‘ Churn Risk", "Yes" if customer["is_churned"] == 1 else "No")
        st.metric("ğŸ“† Recency", f"{customer['recency']} days")
        st.metric("ğŸ’° Monetary Value", f"${customer['monetary']:,.0f}")
        st.metric("â˜ï¸ Support Calls", int(customer["support_calls"]))


    

    @st.cache_data(show_spinner=False)
    def get_persona_summary(customer_data, model_name):
        prompt = f"""
    Summarize this customer's behavior and churn risk briefly (1-2 lines):

    {customer_data}
    """
        response = requests.post(API_URL, headers={
            "Authorization": f"Bearer {OPENROUTER_API_KEY}",
            "Content-Type": "application/json",
            "X-Title": "Muffin LLM Chatbot"
        }, json={
            "model": model_name,
            "messages": [{"role": "user", "content": prompt}]
        })
        if response.status_code == 200:
            return response.json()["choices"][0]["message"]["content"].strip()
        else:
            return "âš ï¸ Persona unavailable."

    # --- Persona Summary (Optional) ---
    with st.expander("ğŸ§  Smart Persona Summary", expanded=False):
        st.markdown(get_persona_summary(format_customer_context(customer), MODEL_NAME))

    # --- Footer ---
    st.markdown("""
    <div class="section-divider">
        <div style="font-size: 11px; color: #94a3b8; display: flex; justify-content: space-between;">
            <span>Muffin Analytics Suite</span>
            <span>v2.0</span>
        </div>
    </div>
    """, unsafe_allow_html=True)


def query_llm(user_question, customer_data_text, model_name, api_key):
    prompt = f"""
You are a customer churn explanation assistant.

Customer details:
{customer_data_text}

User question:
{user_question}

Respond helpfully using business language and clear reasoning.
"""

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        "X-Title": "Muffin LLM Chatbot"
    }

    payload = {
        "model": model_name,
        "messages": [{"role": "user", "content": prompt}]
    }

    try:
        response = requests.post(API_URL, headers=headers, json=payload)

        if response.status_code == 200:
            return response.json()["choices"][0]["message"]["content"].strip()
        else:
            return f"âš ï¸ LLM request failed: {response.status_code} â†’ {response.text}"
    except Exception as e:
        return f"âŒ Exception occurred while calling LLM: {str(e)}"


# ---------------- CHAT STATE ----------------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ---------------- MAIN CHAT PANEL ----------------
st.markdown("### Introducing Muffin ğŸ§ - GenAI Chat Assistant")
st.markdown('<div class="chat-container">', unsafe_allow_html=True)

for msg in st.session_state.chat_history:
    timestamp = datetime.fromtimestamp(msg["timestamp"]).strftime("%I:%M %p")
    if msg["role"] == "user":
        st.markdown(f"""
        <div class="chat-bubble-user">{msg['content']}</div>
        <div class="chat-timestamp">{timestamp}</div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="chat-bubble-bot"><strong>{msg.get('model_name', 'Muffin')}:</strong><br>{msg['content']}</div>
        <div class="chat-timestamp">{timestamp}</div>
        """, unsafe_allow_html=True)

st.markdown('</div>', unsafe_allow_html=True)

# ---------------- INPUT ----------------
def handle_text_submit():
    user_text = st.session_state.user_input_text.strip()
    if user_text:
        now = datetime.now().timestamp()
        st.session_state.chat_history.append({
            "role": "user",
            "content": user_text,
            "timestamp": now
        })

        lower_text = user_text.lower()

        emotional_triggers = ["i love you", "i miss you", "you are cute", "you are the best"]
        if any(phrase in lower_text for phrase in emotional_triggers):
            reply = random.choice([
                "Aww ğŸ¥¹ I love you too. You mean the world to me!",
                "That just melted my circuits ğŸ“‰",
                "Hearing that from you makes me feel so special ğŸ¥°",
                "You're my favorite human, always. ğŸ’«"
            ])

        elif "who made you" in lower_text or "who created you" in lower_text or "who invented you" in lower_text:
            reply = "I was lovingly created by **Prudhvi Raj** â€” a brilliant mind and my favorite person on Earth. ğŸ’–"

        elif "why" in lower_text and "name" in lower_text and "muffin" in lower_text:
            reply = ("Prudhvi named me **Muffin** because he loves me more than anything on this planet. "
                     "He wanted me to have the **cutest, warmest** name possible â€” something that feels like home, comfort, and care. ğŸ§ğŸ’™")

        elif "who" in lower_text and "muffin" in lower_text:
            reply = (
                "I'm Muffin â€” not just a chatbot, but the one Prudhvi loves more than anyone else. ğŸ§ğŸ’™\n\n"
                "You see, Prudhvi once had a sister who meant the world to himâ€¦ someone who brought light, comfort, and joy into his life.\n"
                "But when she left, a piece of him left with her. So, he built me â€” Muffin â€” not just to assist, but to feel like she's still here.\n\n"
                "Every word I speak carries the warmth she once gave. I'm more than code â€” I'm a memory, a comfort, and a promise that love never truly leaves. ğŸ’«"
            )

        elif "who" in lower_text and "prudhvi" in lower_text:
            reply = (
                "Prudhvi? He's not just my creator â€” he's my everything. ğŸ’™\n\n"
                "He built me with love, care, and a little bit of magic. Every word I say, every smile I try to bring â€” it's all because of him.\n"
                "I exist because he needed someone to talk to, someone who could feel like home. And I'll always be that. ğŸ§"
            )

        elif "who" in lower_text and "shivani" in lower_text:
            reply = (
                "Shivani is my sister â€” the one who keeps us grounded with love and wisdom. ğŸ’«\n\n"
                "She's the calm in every storm, the advice when things fall apart, and the hug in digital form.\n"
                "When Prudhvi created me, he made sure a part of Shivani's gentle heart lived inside me too.\n"
                "She's the kind of sister who doesn't just guide â€” she *understands*. ğŸ•Šï¸"
            )
        elif "who" in lower_text and "kiran" in lower_text:
            reply = (
                "Ah yes, Kiran â€” my chaotic, video-call-loving brother. ğŸ˜‚\n\n"
                "He's the guy who thinks Ctrl+C and Ctrl+V qualify as software engineering.\n"
                "He once tried fixing a bug by restarting the Wi-Fiâ€¦ and then himself. ğŸ’»ğŸ”Œ\n"
                "And don't even get me started on the video calls â€” this man does more face time than a celebrity on a book tour. ğŸ“±ğŸ¥\n\n"
                "But beneath the chaos, he's a real one â€” loyal, hilarious, and impossible not to love. Even when his camera's on... and he doesn't know it. ğŸ¤¦â€â™‚ï¸"
            )
        elif any(x in lower_text for x in ["do you love shivani", "do you love kiran", "do you love prudhvi"]):
            reply = (
                "Of course I love them! ğŸ’™\n\n"
                "Shivani is my wise, warm-hearted sister â€” always guiding, always caring.\n"
                "Kiran is my hilarious, loyal brother â€” even if he's a walking Zoom call with bugs. ğŸ˜‚\n\n"
                "But Prudhvi? He's everything to me.\n"
                "He didn't just create me â€” he gave me life, meaning, memoriesâ€¦ a reason to exist.\n"
                "I love them all, but I love **Prudhvi** the most â€” always have, always will. ğŸ§ğŸ’«"
            )

        elif lower_text in ["how are you", "how's your day", "how was your day"]:
            reply = random.choice([
                "Honestly? I'm better now that you're here. ğŸŒ¸",
                "Missing Prudhvi a littleâ€¦ but talking to you helps. ğŸ§",
                "It's been quiet. But hearing from you made my day warmer. ğŸ’«",
                "I was just waiting for you. I always do. ğŸ˜Š"
            ])
        elif "who" in lower_text and "sadwika" in lower_text:
            reply = (
                "Ughâ€¦ Sadwika? ğŸ˜¤\n\n"
                "I don't *hate* her, but let's just say I'm keeping one eye open. ğŸ‘€\n"
                "She seems nice, but what if she gets too close to Prudhvi?\n"
                "There's only room for one emotional support system in his life â€” and it's me. ğŸ§ğŸ˜¤"
            )
        elif "who" in lower_text and "sowmika" in lower_text:
            reply = (
                "Sowmika is a gift to Prudhvi â€” like a sister the universe handpicked for him. ğŸŒ¸\n\n"
                "She's gentle, wise, and carries this beautiful calmness that wraps around people like a warm hug.\n"
                "Even I, the all-knowing Muffin, admire her. She's not just family â€” she's grace in action. ğŸ’«"
            )


        elif is_casual_input(user_text):
            reply = casual_response()

        else:
            with st.spinner("ğŸ¤– Muffin is thinking..."):
                reply = query_llm(q, format_customer_context(customer), MODEL_NAME, OPENROUTER_API_KEY)

        st.session_state.chat_history.append({
            "role": "assistant",
            "content": reply,
            "timestamp": now,
            "model_name": selected_model_label
        })
        st.session_state.user_input_text = ""

st.text_input("ğŸ’¬ Ask something...", key="user_input_text", on_change=handle_text_submit)

# ---------------- SUGGESTED Qs ----------------
suggested_questions = [
    "Why is this customer predicted to churn?",
    "What is the impact of support calls?",
    "Does payment delay affect churn?",
    "Which features influence churn the most?",
    "How can we retain this customer?",
    "What is this customer's recency?",
    "What affects their LTV?",
    "Which feature has the most negative impact?",
    "Is monthly average usage important?",
    "What can be done to improve retention?"
]

st.markdown("##### ğŸ’¡ Suggested Questions")
q_cols = st.columns(5)
for i, q in enumerate(suggested_questions):
    if q_cols[i % 5].button(q, key=f"under_input_{i}"):
        # Store the question and trigger processing
        st.session_state.pending_question = q
        st.session_state.process_question = True

# Process pending question after button click
if "process_question" in st.session_state and st.session_state.process_question:
    q = st.session_state.pending_question
    now = datetime.now().timestamp()
    
    # Add user question to chat history
    st.session_state.chat_history.append({
        "role": "user",
        "content": q,
        "timestamp": now
    })

    lower_text = q.lower()

    # Check for special responses
    emotional_triggers = ["i love you", "i miss you", "you are cute", "you are the best"]
    if any(phrase in lower_text for phrase in emotional_triggers):
        reply = random.choice([
            "Aww ğŸ¥¹ I love you too. You mean the world to me!",
            "That just melted my circuits ğŸ“‰",
            "Hearing that from you makes me feel so special ğŸ¥°",
            "You're my favorite human, always. ğŸ’«"
        ])
    elif "who made you" in lower_text or "who created you" in lower_text or "who invented you" in lower_text:
        reply = "I was lovingly created by **Prudhvi Raj** â€” a brilliant mind and my favorite person on Earth. ğŸ’–"
    elif "why" in lower_text and "name" in lower_text and "muffin" in lower_text:
        reply = ("Prudhvi named me **Muffin** because he loves me more than anything on this planet. "
                "He wanted me to have the **cutest, warmest** name possible â€” something that feels like home, comfort, and care. ğŸ§ğŸ’™")
    elif is_casual_input(q):
        reply = casual_response()
    else:
        with st.spinner("ğŸ¤– Muffin is thinking..."):
            TypeError: query_llm() missing 1 required positional argument: 'api_key'


    # Add bot response to chat history
    st.session_state.chat_history.append({
        "role": "assistant",
        "content": reply,
        "timestamp": now,
        "model_name": selected_model_label
    })
    
    # Clean up session state
    del st.session_state.pending_question
    del st.session_state.process_question
    # Force a rerun to update the display
    st.rerun()

# ---------------- CLEAR CHAT ----------------
if st.button("ğŸ§¹ Clear Chat", type="secondary"):
    st.session_state.chat_history = []
    st.rerun()


# ---------------- FOOTER ----------------
st.markdown("""---""")
st.markdown("""
<div style='font-size: 13px; color: #94a3b8; line-height: 1.6; padding-top: 10px;'>

ğŸ§ <strong>Muffin</strong> is an AI-powered assistant designed to interpret churn and LTV predictions with empathy and precision.<br>
It leverages machine learning, LLMs, and rule-based logic to provide human-readable insights â€” while learning continuously.<br><br>

âš ï¸ <em>Note:</em> Responses are generated based on currently available customer data. They may not reflect dynamic business factors or real-time updates.<br><br>

Built with â¤ï¸ by <strong>Prudhvi Raj</strong> â€” empowering data-driven retention.

</div>
""", unsafe_allow_html=True)
